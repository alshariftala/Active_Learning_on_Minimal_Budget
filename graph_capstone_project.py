# -*- coding: utf-8 -*-
"""Graph_Capstone_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lq-c_jx2qDMkfYcpf3emipy0X-Q-Vacw
"""

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import random
import plotly
import plotly.offline as py
import pandas as pd
from sklearn.metrics import pairwise_distances
from scipy.stats import entropy
from sklearn.neighbors import kneighbors_graph
from tensorflow.examples.tutorials.mnist import input_data
# %matplotlib inline

mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
# make sure the images are np.array type
# checking the shape of the training set
type(mnist.train.images) , mnist.train.images.shape

# the labels are np.array and already hot encoded
mnist.train.labels.shape

X_train=mnist.train.images/255.
# X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)
y_train = mnist.train.labels

X_test= mnist.test.images/255.
# X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)
y_test = mnist.test.labels

X_train.shape ,  y_train.shape ,  X_test.shape  , y_test.shape

tf.reset_default_graph()

regularizer = tf.contrib.layers.l2_regularizer(scale=0.001)
is_training = tf.placeholder_with_default(True, shape=[])
X = tf.placeholder(dtype=tf.float32, shape=(None, 784), name='X')
y = tf.placeholder(dtype=tf.float32, shape=(None, 10), name='y')

# input layer
input_layer = tf.reshape(X, [-1, 28, 28, 1])
net=input_layer

  # CNN Layers
net = tf.layers.batch_normalization(net, training=is_training)
net = tf.layers.conv2d(inputs=net,filters=64, kernel_size=[5, 5], activation=tf.nn.relu, kernel_regularizer=regularizer)
net = tf.layers.max_pooling2d(inputs=net, pool_size=[2, 2], strides=2)

net = tf.layers.batch_normalization(net, training=is_training)
net = tf.layers.conv2d(inputs=net, filters=128,kernel_size=[5, 5],activation=tf.nn.relu, kernel_regularizer=regularizer)
net = tf.layers.max_pooling2d(inputs=net, pool_size=[2, 2], strides=2)

net=tf.layers.flatten(inputs=net)
net = tf.layers.batch_normalization(net, training=is_training)
net=tf.layers.dense(inputs=net, units=1024, activation=tf.nn.relu, kernel_regularizer=regularizer)
  # dropout = tf.layers.dropout(inputs=dense, rate=0.5, training=is_training)


  # output layer
y_hat = tf.layers.dense(net, 10, name='y_hat', activation=None, kernel_regularizer=regularizer)
y_hat_activated = tf.nn.softmax(y_hat)

  # loss function
loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=y_hat)

lr = tf.placeholder_with_default(0.01, shape=[])
gd = tf.train.AdagradOptimizer(lr)
training_op = tf.contrib.training.create_train_op(loss, gd)

y.dtype, y_hat.dtype

# graph based
init = tf.global_variables_initializer()
NUM_EX = 2000
BATCH_SIZE = 25
COLLECTIONS = 10
SIZE_SELECTION = 50

first_time = True

SELECTED = list(range(50))
with tf.Session() as sess:
    init.run()

    for c in range(COLLECTIONS):

        # TAKE WHAT WE HAVE
        x_known = X_train[SELECTED]
        y_known = y_train[SELECTED]


        for epoch in range(2):
            for i in range(0, len(SELECTED), BATCH_SIZE):
                print('%i. Training on range %i:%i' % (epoch, i, i+BATCH_SIZE))
                slice_X = x_known[i:i+BATCH_SIZE]
                slice_y = y_known[i:i+BATCH_SIZE]
                sess.run(training_op, feed_dict={X: slice_X, y: slice_y})
                if first_time:
                    first_time = False
                if i / BATCH_SIZE % 10 == 0:
                    training_loss = sess.run(loss, feed_dict={X: slice_X, y: slice_y})
                    predictions, test_loss = sess.run((y_hat, loss), feed_dict={X: X_test[:1000], y: y_test[:1000]})
                    test_accuracy = np.mean(predictions.argmax(axis=1) == y_test[:1000].argmax(axis=1))
                    print('training loss', training_loss.mean(), 'test loss', test_loss.mean(), 'test accuracy', test_accuracy)


        predictions = sess.run(y_hat_activated, feed_dict={X: X_train[:NUM_EX]})

        distance = pairwise_distances(predictions,metric='euclidean')  # cosine


        from sklearn.manifold import TSNE
        dist=np.asmatrix(distance)
        projection = TSNE(n_components=2, verbose=1, perplexity=40, learning_rate=10, n_iter=3000, metric='precomputed').fit_transform(dist)


        for s in range(SIZE_SELECTION):
          fig = plt.figure()
          axis = fig.add_axes([0, 0, 1, 1])

          df=pd.DataFrame(distance[SELECTED]).min()
          next_one=df.idxmax(axis=0)
          SELECTED.append(next_one)

          remaining= set(range(NUM_EX))-set(SELECTED)
          remaining= list(remaining)

          axis.scatter(projection[remaining,0], projection[remaining,1], c='y')
          selected= projection[SELECTED]
          axis.scatter(selected[:,0],selected[:,1], c='r')
          axis.scatter(projection[next_one,0], projection[next_one,1], c='b')


#       
          print(len(SELECTED))
          plt.show()
